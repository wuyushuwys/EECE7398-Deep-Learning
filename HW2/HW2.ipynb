{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=128):\n",
    "    \"\"\"\n",
    "    Download and load the data\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root='./data.cifar10', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='./data.cifar10', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    return train_loader, test_loader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 5, stride=1)\n",
    "        self.conv1_bn = torch.nn.BatchNorm2d(32)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3)\n",
    "        self.conv2_bn = torch.nn.BatchNorm2d(64)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, 3)\n",
    "        self.conv3_bn = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(128 * 2 * 2, 120)\n",
    "        self.fc1_bn = torch.nn.BatchNorm1d(120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc2_bn = torch.nn.BatchNorm1d(84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.dropout1d = torch.nn.Dropout(0.3)\n",
    "        self.dropout2d = torch.nn.Dropout2d(0.3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.dropout2d(x)\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = self.dropout2d(x)\n",
    "        x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
    "        x = self.dropout2d(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.flatten_feature(x))\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = self.dropout1d(x)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.dropout1d(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def flatten_feature(self, x):\n",
    "        num_feature = 1\n",
    "        for d in x.size()[1:]:\n",
    "            num_feature *= d\n",
    "        return num_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, inputs, device, criterion=None, flag='test'):\n",
    "    net.eval()\n",
    "    if flag == 'inference':\n",
    "        with torch.no_grad():\n",
    "            image = inputs.to(device)\n",
    "            output = net(image)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            return predicted.int()\n",
    "    else:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in inputs:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_loss += criterion(outputs, labels)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return 100 * correct / total, float(total_loss/len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "### Epoch [10/500]\t\ttrain accuracy: 70.544%\t\ttrain loss: 0.8506929\t\ttest accuracy: 67.52%\t\ttest loss:0.9279\n",
      "### Epoch [20/500]\t\ttrain accuracy: 77.02%\t\ttrain loss: 0.6803358\t\ttest accuracy: 72.41%\t\ttest loss:0.8077\n",
      "### Epoch [30/500]\t\ttrain accuracy: 80.11%\t\ttrain loss: 0.5964293\t\ttest accuracy: 74.32%\t\ttest loss:0.7481\n",
      "### Epoch [40/500]\t\ttrain accuracy: 81.998%\t\ttrain loss: 0.5445241\t\ttest accuracy: 75.21%\t\ttest loss:0.7213\n",
      "### Epoch [50/500]\t\ttrain accuracy: 83.492%\t\ttrain loss: 0.5021561\t\ttest accuracy: 76.0%\t\ttest loss:0.697\n",
      "### Epoch [60/500]\t\ttrain accuracy: 84.596%\t\ttrain loss: 0.46828\t\ttest accuracy: 76.7%\t\ttest loss:0.6805\n",
      "### Epoch [70/500]\t\ttrain accuracy: 85.66%\t\ttrain loss: 0.4440726\t\ttest accuracy: 77.11%\t\ttest loss:0.6677\n",
      "### Epoch [80/500]\t\ttrain accuracy: 86.34%\t\ttrain loss: 0.4241743\t\ttest accuracy: 77.45%\t\ttest loss:0.6544\n",
      "### Epoch [90/500]\t\ttrain accuracy: 86.904%\t\ttrain loss: 0.4105394\t\ttest accuracy: 77.79%\t\ttest loss:0.6487\n",
      "### Epoch [100/500]\t\ttrain accuracy: 86.988%\t\ttrain loss: 0.4109083\t\ttest accuracy: 77.52%\t\ttest loss:0.6561\n",
      "### Epoch [110/500]\t\ttrain accuracy: 87.682%\t\ttrain loss: 0.388694\t\ttest accuracy: 78.07%\t\ttest loss:0.6386\n",
      "### Epoch [120/500]\t\ttrain accuracy: 88.38%\t\ttrain loss: 0.3727079\t\ttest accuracy: 77.84%\t\ttest loss:0.6377\n",
      "### Epoch [130/500]\t\ttrain accuracy: 88.412%\t\ttrain loss: 0.3692117\t\ttest accuracy: 77.83%\t\ttest loss:0.6404\n",
      "### Epoch [140/500]\t\ttrain accuracy: 88.864%\t\ttrain loss: 0.364839\t\ttest accuracy: 78.19%\t\ttest loss:0.6364\n",
      "### Epoch [150/500]\t\ttrain accuracy: 89.142%\t\ttrain loss: 0.3541732\t\ttest accuracy: 78.6%\t\ttest loss:0.6232\n",
      "### Epoch [160/500]\t\ttrain accuracy: 89.186%\t\ttrain loss: 0.3471146\t\ttest accuracy: 78.15%\t\ttest loss:0.6259\n",
      "### Epoch [170/500]\t\ttrain accuracy: 89.614%\t\ttrain loss: 0.3473439\t\ttest accuracy: 79.01%\t\ttest loss:0.6192\n",
      "### Epoch [180/500]\t\ttrain accuracy: 89.804%\t\ttrain loss: 0.3409328\t\ttest accuracy: 78.92%\t\ttest loss:0.6171\n",
      "### Epoch [190/500]\t\ttrain accuracy: 89.824%\t\ttrain loss: 0.3335277\t\ttest accuracy: 78.79%\t\ttest loss:0.6159\n",
      "### Epoch [200/500]\t\ttrain accuracy: 90.152%\t\ttrain loss: 0.3258838\t\ttest accuracy: 78.7%\t\ttest loss:0.6153\n",
      "### Epoch [210/500]\t\ttrain accuracy: 90.51%\t\ttrain loss: 0.3227079\t\ttest accuracy: 79.08%\t\ttest loss:0.6123\n",
      "### Epoch [220/500]\t\ttrain accuracy: 90.486%\t\ttrain loss: 0.3178461\t\ttest accuracy: 79.04%\t\ttest loss:0.6172\n",
      "### Epoch [230/500]\t\ttrain accuracy: 90.766%\t\ttrain loss: 0.3082985\t\ttest accuracy: 79.43%\t\ttest loss:0.611\n",
      "### Epoch [240/500]\t\ttrain accuracy: 91.07%\t\ttrain loss: 0.3025523\t\ttest accuracy: 79.41%\t\ttest loss:0.6041\n",
      "### Epoch [250/500]\t\ttrain accuracy: 90.742%\t\ttrain loss: 0.3088889\t\ttest accuracy: 79.26%\t\ttest loss:0.6094\n",
      "### Epoch [260/500]\t\ttrain accuracy: 90.854%\t\ttrain loss: 0.3060965\t\ttest accuracy: 79.11%\t\ttest loss:0.6106\n",
      "### Epoch [270/500]\t\ttrain accuracy: 90.912%\t\ttrain loss: 0.3005725\t\ttest accuracy: 79.35%\t\ttest loss:0.6094\n",
      "### Epoch [280/500]\t\ttrain accuracy: 91.238%\t\ttrain loss: 0.2951989\t\ttest accuracy: 79.53%\t\ttest loss:0.6067\n",
      "### Epoch [290/500]\t\ttrain accuracy: 91.472%\t\ttrain loss: 0.2972083\t\ttest accuracy: 79.49%\t\ttest loss:0.6024\n",
      "### Epoch [300/500]\t\ttrain accuracy: 91.478%\t\ttrain loss: 0.2956972\t\ttest accuracy: 79.61%\t\ttest loss:0.6053\n",
      "### Epoch [310/500]\t\ttrain accuracy: 91.78%\t\ttrain loss: 0.2837157\t\ttest accuracy: 79.86%\t\ttest loss:0.5968\n",
      "### Epoch [320/500]\t\ttrain accuracy: 91.644%\t\ttrain loss: 0.2873085\t\ttest accuracy: 79.73%\t\ttest loss:0.6008\n",
      "### Epoch [330/500]\t\ttrain accuracy: 91.634%\t\ttrain loss: 0.2827131\t\ttest accuracy: 79.27%\t\ttest loss:0.6063\n",
      "### Epoch [340/500]\t\ttrain accuracy: 91.712%\t\ttrain loss: 0.2832149\t\ttest accuracy: 79.67%\t\ttest loss:0.6016\n",
      "### Epoch [350/500]\t\ttrain accuracy: 92.06%\t\ttrain loss: 0.2814294\t\ttest accuracy: 79.57%\t\ttest loss:0.5942\n",
      "### Epoch [360/500]\t\ttrain accuracy: 91.54%\t\ttrain loss: 0.28148\t\ttest accuracy: 79.55%\t\ttest loss:0.6044\n",
      "### Epoch [370/500]\t\ttrain accuracy: 91.978%\t\ttrain loss: 0.2770377\t\ttest accuracy: 79.67%\t\ttest loss:0.5983\n",
      "### Epoch [380/500]\t\ttrain accuracy: 92.23%\t\ttrain loss: 0.2707274\t\ttest accuracy: 79.58%\t\ttest loss:0.5903\n",
      "### Epoch [390/500]\t\ttrain accuracy: 91.946%\t\ttrain loss: 0.2761381\t\ttest accuracy: 79.09%\t\ttest loss:0.6043\n",
      "### Epoch [400/500]\t\ttrain accuracy: 92.358%\t\ttrain loss: 0.264679\t\ttest accuracy: 80.01%\t\ttest loss:0.5929\n",
      "### Epoch [410/500]\t\ttrain accuracy: 92.274%\t\ttrain loss: 0.2695147\t\ttest accuracy: 79.35%\t\ttest loss:0.5982\n",
      "### Epoch [420/500]\t\ttrain accuracy: 92.436%\t\ttrain loss: 0.2656631\t\ttest accuracy: 79.85%\t\ttest loss:0.5948\n",
      "### Epoch [430/500]\t\ttrain accuracy: 92.51%\t\ttrain loss: 0.2668919\t\ttest accuracy: 79.53%\t\ttest loss:0.596\n",
      "### Epoch [440/500]\t\ttrain accuracy: 92.482%\t\ttrain loss: 0.2623061\t\ttest accuracy: 79.89%\t\ttest loss:0.591\n",
      "### Epoch [450/500]\t\ttrain accuracy: 92.68%\t\ttrain loss: 0.2624059\t\ttest accuracy: 79.7%\t\ttest loss:0.596\n",
      "### Epoch [460/500]\t\ttrain accuracy: 92.588%\t\ttrain loss: 0.2634644\t\ttest accuracy: 79.6%\t\ttest loss:0.5929\n",
      "### Epoch [470/500]\t\ttrain accuracy: 92.63%\t\ttrain loss: 0.2559167\t\ttest accuracy: 79.71%\t\ttest loss:0.5943\n",
      "### Epoch [480/500]\t\ttrain accuracy: 92.642%\t\ttrain loss: 0.2664435\t\ttest accuracy: 79.59%\t\ttest loss:0.5957\n",
      "### Epoch [490/500]\t\ttrain accuracy: 92.656%\t\ttrain loss: 0.259126\t\ttest accuracy: 79.87%\t\ttest loss:0.5931\n",
      "### Epoch [500/500]\t\ttrain accuracy: 93.144%\t\ttrain loss: 0.2455048\t\ttest accuracy: 80.16%\t\ttest loss:0.587\n",
      "Finish in 5053.019802570343!\n",
      "The best Model for testing accuracy of 80.24% is saving in ./model\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./runs/3_conv_drop_0.3_iter_500')\n",
    "\n",
    "total_epoch = 500\n",
    "\n",
    "\n",
    "train_loader, test_loader, classes = load_data()\n",
    "net = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Using\", torch.cuda.device_count(), \"GPUs\" )\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "net.to(device)\n",
    "    \n",
    "best_test_accuracy = 0\n",
    "old_train_lost = 0\n",
    "start = time()\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        net.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy, train_loss = test(net, train_loader, device, criterion)\n",
    "    test_accuracy, test_loss = test(net, test_loader, device, criterion)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"### Epoch [{}/{}]\\t\\ttrain accuracy: {}%\\t\\ttrain loss: {}\\t\\ttest accuracy: {}%\\t\\ttest loss:{}\"\n",
    "              .format(epoch,total_epoch, train_accuracy, round(train_loss, 7), test_accuracy, round(test_loss, 4)))\n",
    "    writer.add_scalar('Test/Loss', test_loss, epoch)\n",
    "    writer.add_scalar('Test/Accuracy', test_accuracy, epoch)\n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', train_accuracy, epoch)\n",
    "\n",
    "\n",
    "    if best_test_accuracy < test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        if not os.path.isdir('./model'):\n",
    "            os.mkdir('./model')\n",
    "        torch.save(net.state_dict(), \"./model/fc.pt\")\n",
    "        # print(\"### Epoch {}\\t\\tSave Model fot test accuracy {}% \".format(epoch+1, best_test_accuracy))\n",
    "    if abs(old_train_lost-train_loss) < 1e-5:\n",
    "        print(\"Training almost converge in Epoch {}, STOP!\".format(epoch))\n",
    "print(\"Finish in {}!\".format(time()-start))\n",
    "print(\"The best Model for testing accuracy of {}% is saving in ./model\".format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(images[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Net(\\n  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\\n  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\\n  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\\n  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (fc1): Linear(in_features=512, out_features=120, bias=True)\\n  (fc1_bn): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\\n  (fc2_bn): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\\n  (dropout1d): Dropout(p=0.3, inplace=False)\\n  (dropout2d): Dropout2d(p=0.3, inplace=False)\\n)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
